"use strict";(self.webpackChunkrke_docs=self.webpackChunkrke_docs||[]).push([[5483],{3905:(n,e,t)=>{t.d(e,{Zo:()=>c,kt:()=>f});var o=t(7294);function a(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}function r(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(n);e&&(o=o.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),t.push.apply(t,o)}return t}function i(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?r(Object(t),!0).forEach((function(e){a(n,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))}))}return n}function l(n,e){if(null==n)return{};var t,o,a=function(n,e){if(null==n)return{};var t,o,a={},r=Object.keys(n);for(o=0;o<r.length;o++)t=r[o],e.indexOf(t)>=0||(a[t]=n[t]);return a}(n,e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);for(o=0;o<r.length;o++)t=r[o],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(n,t)&&(a[t]=n[t])}return a}var s=o.createContext({}),p=function(n){var e=o.useContext(s),t=e;return n&&(t="function"==typeof n?n(e):i(i({},e),n)),t},c=function(n){var e=p(n.components);return o.createElement(s.Provider,{value:e},n.children)},u="mdxType",m={inlineCode:"code",wrapper:function(n){var e=n.children;return o.createElement(o.Fragment,{},e)}},d=o.forwardRef((function(n,e){var t=n.components,a=n.mdxType,r=n.originalType,s=n.parentName,c=l(n,["components","mdxType","originalType","parentName"]),u=p(t),d=a,f=u["".concat(s,".").concat(d)]||u[d]||m[d]||r;return t?o.createElement(f,i(i({ref:e},c),{},{components:t})):o.createElement(f,i({ref:e},c))}));function f(n,e){var t=arguments,a=e&&e.mdxType;if("string"==typeof n||a){var r=t.length,i=new Array(r);i[0]=d;var l={};for(var s in e)hasOwnProperty.call(e,s)&&(l[s]=e[s]);l.originalType=n,l[u]="string"==typeof n?n:a,i[1]=l;for(var p=2;p<r;p++)i[p]=t[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}d.displayName="MDXCreateElement"},7484:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var o=t(3117),a=(t(7294),t(3905));const r={title:"Custom Network Plug-in Example"},i=void 0,l={unversionedId:"config-options/add-ons/network-plugins/custom-network-plugin-example/custom-network-plugin-example",id:"config-options/add-ons/network-plugins/custom-network-plugin-example/custom-network-plugin-example",title:"Custom Network Plug-in Example",description:"The below example shows how to configure a custom network plug-in with an in-line add-on to the cluster.yml.",source:"@site/docs/config-options/add-ons/network-plugins/custom-network-plugin-example/custom-network-plugin-example.md",sourceDirName:"config-options/add-ons/network-plugins/custom-network-plugin-example",slug:"/config-options/add-ons/network-plugins/custom-network-plugin-example/",permalink:"/config-options/add-ons/network-plugins/custom-network-plugin-example/",draft:!1,editUrl:"https://github.com/rancher/rke1-docs/edit/main/docs/config-options/add-ons/network-plugins/custom-network-plugin-example/custom-network-plugin-example.md",tags:[],version:"current",lastUpdatedAt:1695166572,formattedLastUpdatedAt:"Sep 19, 2023",frontMatter:{title:"Custom Network Plug-in Example"},sidebar:"mySidebar",previous:{title:"Network Plug-ins",permalink:"/config-options/add-ons/network-plugins/"},next:{title:"DNS providers",permalink:"/config-options/add-ons/dns/"}},s={},p=[],c={toc:p},u="wrapper";function m(n){let{components:e,...t}=n;return(0,a.kt)(u,(0,o.Z)({},c,t,{components:e,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The below example shows how to configure a custom network plug-in with an in-line add-on to the ",(0,a.kt)("inlineCode",{parentName:"p"},"cluster.yml"),"."),(0,a.kt)("p",null,"First, to edit the network plug-ins, change the ",(0,a.kt)("inlineCode",{parentName:"p"},"network")," section of the YAML from:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'network:\n  options:\n    flannel_backend_type: "vxlan"\n  plugin: "canal"\n')),(0,a.kt)("p",null,"to:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"network:\n    plugin: none\n")),(0,a.kt)("p",null,"Then, in the ",(0,a.kt)("inlineCode",{parentName:"p"},"addons")," section of the ",(0,a.kt)("inlineCode",{parentName:"p"},"cluster.yml"),", you can add the add-on manifest of a cluster that has the network plugin-that you want. In the below example, we are replacing the Canal plugin with a Flannel plugin by adding the add-on manifest for the cluster through the ",(0,a.kt)("inlineCode",{parentName:"p"},"addons")," field:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'addons: |-\n    ---\n    kind: ClusterRoleBinding\n    apiVersion: rbac.authorization.k8s.io/v1\n    metadata:\n      name: flannel\n    roleRef:\n      apiGroup: rbac.authorization.k8s.io\n      kind: ClusterRole\n      name: flannel\n    subjects:\n    - kind: ServiceAccount\n      name: flannel\n      namespace: kube-system\n    ---\n    kind: ClusterRole\n    apiVersion: rbac.authorization.k8s.io/v1\n    metadata:\n      name: flannel\n    rules:\n      - apiGroups:\n          - ""\n        resources:\n          - pods\n        verbs:\n          - get\n      - apiGroups:\n          - ""\n        resources:\n          - nodes\n        verbs:\n          - list\n          - watch\n      - apiGroups:\n          - ""\n        resources:\n          - nodes/status\n        verbs:\n          - patch\n    ---\n    kind: ConfigMap\n    apiVersion: v1\n    metadata:\n      name: kube-flannel-cfg\n      namespace: "kube-system"\n      labels:\n        tier: node\n        app: flannel\n    data:\n      cni-conf.json: |\n        {\n          "name":"cbr0",\n          "cniVersion":"0.3.1",\n          "plugins":[\n            {\n              "type":"flannel",\n              "delegate":{\n                "forceAddress":true,\n                "isDefaultGateway":true\n              }\n            },\n            {\n              "type":"portmap",\n              "capabilities":{\n                "portMappings":true\n              }\n            }\n          ]\n        }\n      net-conf.json: |\n        {\n          "Network": "10.42.0.0/16",\n          "Backend": {\n            "Type": "vxlan"\n          }\n        }\n    ---\n    apiVersion: extensions/v1beta1\n    kind: DaemonSet\n    metadata:\n      name: kube-flannel\n      namespace: "kube-system"\n      labels:\n        tier: node\n        k8s-app: flannel\n    spec:\n      template:\n        metadata:\n          labels:\n            tier: node\n            k8s-app: flannel\n        spec:\n          affinity:\n            nodeAffinity:\n              requiredDuringSchedulingIgnoredDuringExecution:\n                nodeSelectorTerms:\n                  - matchExpressions:\n                    - key: beta.kubernetes.io/os\n                      operator: NotIn\n                      values:\n                        - windows\n          serviceAccountName: flannel\n          containers:\n          - name: kube-flannel\n            image: rancher/coreos-flannel:v0.10.0-rancher1\n            imagePullPolicy: IfNotPresent\n            resources:\n              limits:\n                cpu: 300m\n                memory: 500M\n              requests:\n                cpu: 150m\n                memory: 64M\n            command: ["/opt/bin/flanneld","--ip-masq","--kube-subnet-mgr"]\n            securityContext:\n              privileged: true\n            env:\n            - name: POD_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n            volumeMounts:\n            - name: run\n              mountPath: /run\n            - name: cni\n              mountPath: /etc/cni/net.d\n            - name: flannel-cfg\n              mountPath: /etc/kube-flannel/\n          - name: install-cni\n            image: rancher/flannel-cni:v0.3.0-rancher1\n            command: ["/install-cni.sh"]\n            env:\n            # The CNI network config to install on each node.\n            - name: CNI_NETWORK_CONFIG\n              valueFrom:\n                configMapKeyRef:\n                  name: kube-flannel-cfg\n                  key: cni-conf.json\n            - name: CNI_CONF_NAME\n              value: "10-flannel.conflist"\n            volumeMounts:\n            - name: cni\n              mountPath: /host/etc/cni/net.d\n            - name: host-cni-bin\n              mountPath: /host/opt/cni/bin/\n          hostNetwork: true\n          tolerations:\n          - operator: Exists\n            effect: NoSchedule\n          - operator: Exists\n            effect: NoExecute\n          - key: node.kubernetes.io/not-ready\n            effect: NoSchedule\n            operator: Exists\n          volumes:\n            - name: run\n              hostPath:\n                path: /run\n            - name: cni\n              hostPath:\n                path: /etc/cni/net.d\n            - name: flannel-cfg\n              configMap:\n                name: kube-flannel-cfg\n            - name: host-cni-bin\n              hostPath:\n                path: /opt/cni/bin\n      updateStrategy:\n        rollingUpdate:\n          maxUnavailable: 20%\n        type: RollingUpdate\n    ---\n    apiVersion: v1\n    kind: ServiceAccount\n    metadata:\n      name: flannel\n      namespace: kube-system\n')),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Result:")," The cluster is up with the custom network plug-in."))}m.isMDXComponent=!0}}]);